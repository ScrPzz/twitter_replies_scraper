{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d9bbd21-6d2e-4d82-aa88-7195381eddad",
   "metadata": {},
   "source": [
    "### Replies scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "307df1bb-d478-4784-8aeb-7a1ed82f7a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7d9ffae-3da4-48d2-a2b3-614986b16ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_tweet='Full url of the tweet you want to scrape'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef598a34-f8e0-488c-aea9-9ac548b8b87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter Login \n",
    "twitter_usr=\"@your_twitter_username\"\n",
    "twitter_pass='password'\n",
    "\n",
    "def twitter_login(driver, twitter_usr=str, twitter_pass=str):\n",
    "    driver.get('https://twitter.com/i/flow/login')\n",
    "    sleep(6)\n",
    "    user = driver.find_element(by=By.XPATH, value='//*[@autocomplete=\"username\"]')\n",
    "    sleep(1)\n",
    "    user.send_keys(twitter_usr)\n",
    "    sleep(1)\n",
    "    next_btn = driver.find_element(by=By.XPATH, value='/html/body/div/div/div/div[1]/div/div/div/div/div/div/div[2]/div[2]/div/div/div[2]/div[2]/div[1]/div/div/div[6]/div')\n",
    "    next_btn.click()\n",
    "    sleep(4)\n",
    "    psswd_in = driver.find_element(by=By.XPATH, value='//*[@autocomplete=\"current-password\"]')\n",
    "    psswd_in.send_keys(twitter_pass)\n",
    "    sleep(2)\n",
    "    login_btn = driver.find_element(by=By.XPATH, value='//html/body/div/div/div/div[1]/div/div/div/div/div/div/div[2]/div[2]/div/div/div[2]/div[2]/div[2]/div/div[1]/div/div/div')\n",
    "    login_btn.click()\n",
    "    sleep(3)\n",
    "    print('Login Successful')\n",
    "    return driver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39181426-f4b0-45ad-a34f-9e272d2a0743",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Firefox(service=Service(GeckoDriverManager().install()))\n",
    "\n",
    "twitter_login(driver, twitter_usr=twitter_usr, twitter_pass=twitter_pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8078dcf-898e-4542-872f-5ddd25608615",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "\n",
    "driver.get(TARGET_TWEET)\n",
    "\n",
    "time.sleep(6)\n",
    "\n",
    "MAX_SCROLLS=5\n",
    "for _ in range(MAX_SCROLLS):\n",
    "    last = driver.find_elements(By.XPATH, '//div[@data-testid=\"cellInnerDiv\"]')[-1]\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView(true)\", last)\n",
    "    time.sleep(.2)\n",
    "    all_tweets = driver.find_elements(By.XPATH, '//div[@data-testid]//article[@data-testid=\"tweet\"]')\n",
    "    for item in all_tweets[1:]: # skip first tweet because it is BBC tweet\n",
    " \n",
    "            try:\n",
    "                date = item.find_element(By.XPATH, './/time').text\n",
    "            except:\n",
    "                date = '[empty]'\n",
    "\n",
    "            try:\n",
    "                text = item.find_element(By.XPATH, './/div[@data-testid=\"tweetText\"]').text\n",
    "            except:\n",
    "                text = '[empty]'\n",
    "\n",
    "\n",
    "            try:\n",
    "                replying_to = item.find_element(By.XPATH, './/div[contains(text(), \"Replying to\")]//a').text\n",
    "            except:\n",
    "                replying_to = '[empty]'\n",
    "            \n",
    "            tweets.append([date, replying_to, text])\n",
    "            time.sleep(.2)\n",
    "            \n",
    "print(f'Found {len(tweets)} replies.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b2e5517-1aea-42bb-880a-eda84bc80034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found more replies!\n"
     ]
    }
   ],
   "source": [
    "# Scraping the replies loaded by the 'load more replies' button, if there are such. \n",
    "#The \"load more replies\" XPATH changes dinamically and i cannot figure out the mechanics, so for now i'm brute-forcing it.\n",
    "# Filling the missing values with None \n",
    "\n",
    "for i in range(20):\n",
    "    try:\n",
    "        show_more=driver.find_element(By.XPATH, value=f'/html/body/div[1]/div/div/div[2]/main/div/div/div/div[1]/div/section/div/div/div[{i}]/div/div/div/div/div/span')\n",
    "        show_more.click()\n",
    "        print('Found more replies!')\n",
    "        for _ in range(MAX_SCROLLS):\n",
    "            last = driver.find_elements(By.XPATH, '//div[@data-testid=\"cellInnerDiv\"]')[-1]\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView(true)\", last)\n",
    "            time.sleep(.2)\n",
    "            all_tweets = driver.find_elements(By.XPATH, '//div[@data-testid]//article[@data-testid=\"tweet\"]')\n",
    "            for item in all_tweets: # skip first tweet because it is BBC tweet\n",
    "\n",
    "                    try:\n",
    "                        date = item.find_element(By.XPATH, './/time').text\n",
    "                    except:\n",
    "                        date = None\n",
    "\n",
    "                    try:\n",
    "                        text = item.find_element(By.XPATH, './/div[@data-testid=\"tweetText\"]').text\n",
    "                    except:\n",
    "                        text = None\n",
    "\n",
    "                    try:\n",
    "                        replying_to = item.find_element(By.XPATH, './/div[contains(text(), \"Replying to\")]//a').text\n",
    "                    except:\n",
    "                        replying_to = None\n",
    "\n",
    "                    tweets.append([date, replying_to, text])\n",
    "                    time.sleep(.2)\n",
    "\n",
    "        print(f'Found {len(tweets)} replies totally.')\n",
    "        driver.quit()\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1993603-645f-4ea2-8f34-b4f3a8af3aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of dataframe construction\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(tweets, columns=['Date of Tweet', 'Replying to', 'Tweet'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f41fcb0-7f50-4968-b5dd-d77811e7ec10",
   "metadata": {},
   "source": [
    "## TO DO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a0dbe9b-a456-49b1-91d5-36fba1bf7e1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ce9e84-efcd-47e6-8cfb-11d12e8d44fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
